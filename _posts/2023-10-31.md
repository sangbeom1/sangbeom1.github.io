---
layout: single
title: "39장 DOM"
categories: javascript
tag: [python, blog]
toc: true
author_profile: false
sidebar:
  nav: "docs"
toc: true
---

5. Callback
   1. 저장기능<br>
      데이터사이즈가 커지거나 이미지처럼 볼륨양이 많아지면 학습하는데 시간이 오래걸립니다.<br>
      만약 5시간동안 학습하는데 갑자기 전원이 꺼져버린다면 다시 시작해야하는 문제가 생깁니다.<br>
      이러한 문제를 해결하기위해 학습중 계속해서 저장을 해야합니다.<br>
      Model Check Point라는 콜백을 이용해서 학습 중간중간에 저장합니다.<br>
   2. 조기종료<br>
      더이상 학습하는게 의미가 없겠다는 판단이 들면 종료해버리는 기능입니다.<br>
      `Keras`에서 `Early Stopping`이라는 기능으로 제공됩니다.<br>
   3. Learning rate의 동적 제어<br>
      epoch을 돌면서 Learning rate가 바뀝니다. 이미 optimizer에 탑재되어있어 사용하지 않습니다.

### 모델 저장기능: Model Check Point

```python
from tensorflow.keras.callbacks import ModelCheckpoint

# save_weight: w와 b만 저장할건지 모델 구조도 같이 저장할건지를 정합니다.
#   True는 모델 가중치만 저장됩니다. 파일 사이즈가 작습니다. 나중에 저장된 파일을 불러올 때는 모델을 다시 만들어주어야 합니다.
#   False 모델 가중치 뿐만 아니라 모델 구조도 저장됩니다.
# save_best_only가 False이면 매 epoch마다 저장됩니다. epoch이 증가할 때 마다 가중치가 좋아지는 것은 아닙니다.
# save_best_only가 True이면 가중치가 이전보다 좋은경우에만 저장합니다.
modelcp = ModelCheckpoint( # ModelCheckpoint 객체를 생성합니다.
                          filepath='/tmp_checkpoint.ckpt', # 모델은 파일에 저장되므로 파일 경로를 전달
                          save_weights_only=True,
                          save_best_only=True,
                          monitor='val_loss', # 어떤 것을 기준으로 좋은지 아닌지를 판단. 일반적으로 'val_loss'를 사용
                          verbose=1 # verbose는 save되었을 때 화면에 출력할건지 안할건지
                          )

model.fit(
          x_data_train,
          t_data_train,
          epochs=200,
          verbose=1,
          batch_size=100,
          validation_split=0.3,
          callbacks=[modelcp]
          )

# 나중에 파일로 저장되어 있는 이 ModelCheckpoint 파일을 로드하려면
# 모델의 구조는 존재해야하고 ModelCheckpoint에는 가중치만 존재합니다.
model.load_weights('tmp_checkpoint.ckpt')
```

# 학습의 조기종료: EarlyStopping

```python
from tensorflow.keras.callback import EarlyStopping

# patience란 참는 횟수를 말합니다.
# 1 epoch : val_loss => 0.1 ↓
# 1 epoch : val_loss => 0.05 ↓
# 1 epoch : val_loss => 0.04 ↓
# 1 epoch : val_loss => 0.05 ↑ (1회 참기)
# 1 epoch : val_loss => 0.044 ↑ (2회 참기)
# 1 epoch : val_loss => 0.03 ↓ (리셋)

# 학습이 끝난 후 가장 좋은 weigth값으로 모델의 weight값을 설정
# epoch이 지나면서 weight값은 계속 바뀌지만 학습이 끝났을 때 가장 weight가 좋은 값으로 전달할지 설정합니다.
es = EarlyStopping(
                    monitor='val_loss', # 어떤 조건을 가지고 종료시킬지 진행할지를 정합니다.
                    patience=3,
                    restor_best_weights=True
                  )
model.fit(
          x_data_train,
          t_data_train,
          epochs=200,
          verbose=1,
          batch_size=100,
          validation_split=0.3,
          callbacks=[modelcp, es]
          )
```
